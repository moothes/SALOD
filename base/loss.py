import torch
from torch import nn
from torch.nn import functional as F
from .util import *

from math import exp

def structure(pred, mask, config):
    weit = 1 + 5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)
    wbce = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')
    wbce = (weit*wbce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))

    pred = torch.sigmoid(pred)
    inter = ((pred * mask)*weit).sum(dim=(2, 3))
    union = ((pred + mask)*weit).sum(dim=(2, 3))
    wiou = 1 - (inter + 1)/(union - inter+1)
    return (wbce + wiou).mean()


def floss(prediction, target, beta=0.3, log_like=False):
    prediction = torch.sigmoid(prediction)
    EPS = 1e-10
    N = N = prediction.size(0)
    TP = (prediction * target).view(N, -1).sum(dim=1)
    H = beta * target.view(N, -1).sum(dim=1) + prediction.view(N, -1).sum(dim=1)
    fmeasure = (1 + beta) * TP / (H + EPS)
    if log_like:
        floss = -torch.log(fmeasure)
    else:
        floss  = (1 - fmeasure)
    floss = floss.mean()
    return floss

def eval_pr(y_pred, y, num):
    prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()
    # thlist = torch.linspace(0, 1 - 1e-10, num).cuda()
    thlist = torch.linspace(0, 1, num).cuda()

    for i in range(num-1):
        y_temp = torch.logical_and(y_pred>= thlist[i], y_pred < thlist[i+1]).float()
        #y_temp = (y_pred >= thlist[i] ).float()
        tp = (y_temp * y).sum()
        prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)
    return prec, recall

def pr(pred, gt, config):
    pred = torch.sigmoid(pred)
    prec, recall = eval_pr(pred, gt, 255)
    prec_loss = 1.0 - prec
    recall_loss = 1.0 - recall
    prec_loss = prec_loss.mean()
    recall_loss = recall_loss.mean()

    loss = prec_loss + recall_loss

    return  loss

def eval_pr_original(y_pred, y, num):
    prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()
    # thlist = torch.linspace(0, 1 - 1e-10, num).cuda()
    thlist = torch.linspace(0, 1, num).cuda()

    for i in range(num):
        y_temp = (y_pred >= thlist[i]).float()
        tp = (y_temp * y).sum()
        prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)
    return prec, recall

def object(pred, gt) -> float:
    """
    Calculate the object score.
    """
    fg = pred * gt
    bg = (1 - pred) * (1 - gt)
    u = torch.mean(gt)
    object_score = u * s_object(fg, gt) + (1 - u) * s_object(bg, 1 - gt)
    return object_score

_EPS = np.spacing(1)
def s_object(pred, gt) -> float:
    x = torch.mean(pred[gt == 1])
    sigma_x = torch.std(pred[gt == 1], unbiased=True)
    score = 2 * x / (torch.pow(x, 2) + 1 + sigma_x + _EPS)
    return score

def region( pred, gt) -> float:
    """
    Calculate the region score.
    """
    x, y = centroid(gt)
    part_info = divide_with_xy(pred, gt, x, y)
    w1, w2, w3, w4 = part_info["weight"]
    # assert np.isclose(w1 + w2 + w3 + w4, 1), (w1 + w2 + w3 + w4, pred.mean(), gt.mean())

    pred1, pred2, pred3, pred4 = part_info["pred"]
    gt1, gt2, gt3, gt4 = part_info["gt"]
    score1 = ssim(pred1, gt1)
    score2 = ssim(pred2, gt2)
    score3 = ssim(pred3, gt3)
    score4 = ssim(pred4, gt4)

    return w1 * score1 + w2 * score2 + w3 * score3 + w4 * score4

def centroid(matrix) -> tuple:
    """
    To ensure consistency with the matlab code, one is added to the centroid coordinate,
    so there is no need to use the redundant addition operation when dividing the region later,
    because the sequence generated by ``1:X`` in matlab will contain ``X``.

    :param matrix: a data array
    :return: the centroid coordinate
    """
    h, w = matrix.shape
    if matrix.sum() == 0:
        x = torch.round(w / 2)
        y = torch.round(h / 2)
    else:
        area_object = torch.sum(matrix)
        row_ids = torch.arange(h).cuda()
        col_ids = torch.arange(w).cuda()
        x = torch.round(torch.sum(torch.sum(matrix, axis=0) * col_ids) / area_object)
        y = torch.round(torch.sum(torch.sum(matrix, axis=1) * row_ids) / area_object)
    return int(x) + 1, int(y) + 1

def divide_with_xy(pred, gt, x: int, y: int) -> dict:
    """
    Use (x,y) to divide the ``pred`` and the ``gt`` into four submatrices, respectively.
    """
    h, w = gt.shape
    area = h * w

    gt_LT = gt[0:y, 0:x]
    gt_RT = gt[0:y, x:w]
    gt_LB = gt[y:h, 0:x]
    gt_RB = gt[y:h, x:w]

    pred_LT = pred[0:y, 0:x]
    pred_RT = pred[0:y, x:w]
    pred_LB = pred[y:h, 0:x]
    pred_RB = pred[y:h, x:w]

    w1 = x * y / area
    w2 = y * (w - x) / area
    w3 = (h - y) * x / area
    w4 = 1 - w1 - w2 - w3

    return dict(
        gt=(gt_LT, gt_RT, gt_LB, gt_RB),
        pred=(pred_LT, pred_RT, pred_LB, pred_RB),
        weight=(w1, w2, w3, w4),
    )

def ssim(pred, gt) -> float:
    """
    Calculate the ssim score.
    """
    h, w = pred.shape
    N = h * w

    x = torch.mean(pred)
    y = torch.mean(gt)

    sigma_x = torch.sum((pred - x) ** 2) / (N - 1)
    sigma_y = torch.sum((gt - y) ** 2) / (N - 1)
    sigma_xy = torch.sum((pred - x) * (gt - y)) / (N - 1)

    alpha = 4 * x * y * sigma_xy
    beta = (x ** 2 + y ** 2) * (sigma_x + sigma_y)

    if alpha != 0:
        score = alpha / (beta + _EPS)
    elif alpha == 0 and beta == 0:
        score = 1
    else:
        score = 0
    return score


def Sm(pred, gt):
    """
    Calculate the S-measure.

    :return: s-measure
    """
    alpha = 0.5
    y = torch.mean(gt)
    if y == 0:
        sm = 1 - torch.mean(pred)
    elif y == 1:
        sm = torch.mean(pred)
    else:
        sm = alpha * object(pred, gt) + (1 - alpha) * region(pred, gt)
        sm = max(0, sm)
    return sm


def sm(pred, mask):
    sm = 0.0
    pred = torch.sigmoid(pred)
    for i in range(pred.shape[0]):
        sm += Sm( pred=pred[i,0,:], gt=mask[i,0,:])
    sm = sm / pred.shape[0]
    sm_loss = 1.0 - sm
    return sm_loss


def _object(pred, gt):
    temp = pred[gt == 1]
    x = temp.mean()
    sigma_x = temp.std()
    score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)

    return score

def _S_object(pred, gt):
    fg = torch.where(gt == 0, torch.zeros_like(pred), pred)
    bg = torch.where(gt == 1, torch.zeros_like(pred), 1 - pred)
    o_fg = _object(fg, gt)
    o_bg = _object(bg, 1 - gt)
    u = gt.mean()
    Q = u * o_fg + (1 - u) * o_bg
    return Q

def _S_region(pred, gt):
    X, Y = _centroid(gt)
    gt1, gt2, gt3, gt4, w1, w2, w3, w4 = _divideGT(gt, X, Y)
    p1, p2, p3, p4 = _dividePrediction(pred, X, Y)
    Q1 = _ssim(p1, gt1)
    Q2 = _ssim(p2, gt2)
    Q3 = _ssim(p3, gt3)
    Q4 = _ssim(p4, gt4)
    Q = w1 * Q1 + w2 * Q2 + w3 * Q3 + w4 * Q4
    return Q

def _centroid(gt):
    rows, cols = gt.size()[-2:]
    gt = gt.view(rows, cols)
    if gt.sum() == 0:
        if True:
            X = torch.eye(1).cuda() * round(cols / 2)
            Y = torch.eye(1).cuda() * round(rows / 2)
        else:
            X = torch.eye(1) * round(cols / 2)
            Y = torch.eye(1) * round(rows / 2)
    else:
        total = gt.sum()
        if True:
            i = torch.from_numpy(np.arange(0, cols)).cuda().float()
            j = torch.from_numpy(np.arange(0, rows)).cuda().float()
        else:
            i = torch.from_numpy(np.arange(0, cols)).float()
            j = torch.from_numpy(np.arange(0, rows)).float()
        X = torch.round((gt.sum(dim=0) * i).sum() / total + 1e-20)
        Y = torch.round((gt.sum(dim=1) * j).sum() / total + 1e-20)
    return X.long(), Y.long()

def _divideGT(gt, X, Y):
    h, w = gt.size()[-2:]
    area = h * w
    gt = gt.view(h, w)
    LT = gt[:Y, :X]
    RT = gt[:Y, X:w]
    LB = gt[Y:h, :X]
    RB = gt[Y:h, X:w]
    X = X.float()
    Y = Y.float()
    w1 = X * Y / area
    w2 = (w - X) * Y / area
    w3 = X * (h - Y) / area
    w4 = 1 - w1 - w2 - w3
    return LT, RT, LB, RB, w1, w2, w3, w4

def _dividePrediction(pred, X, Y):
    h, w = pred.size()[-2:]
    pred = pred.view(h, w)
    LT = pred[:Y, :X]
    RT = pred[:Y, X:w]
    LB = pred[Y:h, :X]
    RB = pred[Y:h, X:w]
    return LT, RT, LB, RB

def _ssim(pred, gt):
    gt = gt.float()
    h, w = pred.size()[-2:]
    N = h * w
    x = pred.mean()
    y = gt.mean()
    sigma_x2 = ((pred - x) * (pred - x)).sum() / (N - 1 + 1e-20)
    sigma_y2 = ((gt - y) * (gt - y)).sum() / (N - 1 + 1e-20)
    sigma_xy = ((pred - x) * (gt - y)).sum() / (N - 1 + 1e-20)

    aplha = 4 * x * y * sigma_xy
    beta = (x * x + y * y) * (sigma_x2 + sigma_y2)

    if aplha != 0:
        Q = aplha / (beta + 1e-20)
    elif aplha == 0 and beta == 0:
        Q = 1.0
    else:
        Q = 0
    return Q


def Eval_Smeasure(pred, gt):
    alpha, avg_q, img_num = 0.5, 0.0, 0.0
    y = gt.mean()
    if y == 0:
        x = pred.mean()
        Q = 1.0 - x
    elif y == 1:
        x = pred.mean()
        Q = x
    else:
        gt[gt >= 0.5] = 1
        gt[gt < 0.5] = 0
        Q = alpha * _S_object(pred, gt) + (1 - alpha) * _S_region(pred, gt)
        if Q.item() < 0:
            Q = torch.FloatTensor([0.0])
    #q = Q.item()
    return 1.0 - Q


def gaussian(window_size, sigma):
    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
    return gauss/gauss.sum()

def create_window(window_size, channel):
    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)
    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())
    return window

def _ssim(img1, img2, window, window_size, channel, size_average = True):
    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)
    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1*mu2

    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq
    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq
    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2

    C1 = 0.01**2
    C2 = 0.03**2

    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))

    if size_average:
        return ssim_map.mean()
    else:
        return ssim_map.mean(1).mean(1).mean(1)

def ssim(preds, target, config, window_size=11):
    pred = torch.sigmoid(preds)
    
    c = pred.size()[1]
    window = create_window(window_size, c).cuda()
    ssim_loss = 1 - _ssim(pred, target, window, window_size, c)
    return ssim_loss

def bce(preds, target, config):
    bce = nn.BCEWithLogitsLoss()
    loss = bce(preds, target)
    return loss

def ctloss(preds, target, config):
    bce = nn.BCEWithLogitsLoss(reduction='none')
    
    pred = torch.sigmoid(preds)
    #wm = torch.abs(target - pred)
    #wm = (wm - torch.min(wm)) / (torch.max(wm) - torch.min(wm))
    wm = F.avg_pool2d(label_edge_prediction(target), 3, stride=1, padding=1) * 4 + 1
    
    loss = (bce(preds, target) * wm).mean()
    return loss

def iou(preds, target, config):
    pred = torch.sigmoid(preds)

    inter = torch.sum(target * pred, dim=(1, 2, 3))
    union = torch.sum(target, dim=(1, 2, 3)) + torch.sum(pred, dim=(1, 2, 3)) - inter
    iou_loss = 1 - ((inter+1) / (union+1)).mean()
    return iou_loss

def dice(preds, target, config):
    pred = torch.sigmoid(preds)

    ab = torch.sum(pred * target, dim=(1, 2, 3))
    a = torch.sum(pred, dim=(1, 2, 3))
    b = torch.sum(target, dim=(1, 2, 3))
    # Dice loss with Laplace smoothing
    dice_loss = 1 - (2 * (ab + 1) / (a + b + 1)).mean()
    return dice_loss
    
# boundary dice loss and PBSM
def boundary_dice_loss(pred, mask, config):
    size = max(1, (13 - ((config['cur_epoch'] + 1) // 10) * 2))  # PBSM
    pred = F.sigmoid(pred)
    n    = pred.shape[0]
    mask_boundary = F.max_pool2d(1 - mask, kernel_size=3, stride=1, padding=1)
    mask_boundary -= 1 - mask

    pred_boundary = F.max_pool2d(1 - pred, kernel_size=3, stride=1, padding=1)
    pred_boundary -= 1 - pred
    mask_boundary = F.max_pool2d(mask_boundary, kernel_size=size, stride=1, padding=(size-1)//2)
    pred_boundary = F.max_pool2d(pred_boundary, kernel_size=size, stride=1, padding=(size-1)//2)
    mask_boundary = torch.reshape(mask_boundary, shape=(n, -1))
    pred_boundary = torch.reshape(pred_boundary, shape=(n, -1))

    intersection  = (pred_boundary * mask_boundary).sum(axis=(1))
    unior         = (pred_boundary + mask_boundary).sum(axis=(1))
    dice          = (2 * intersection + 1) / (unior + 1)
    dice          = torch.mean(1 - dice)
    return dice

def fscore(preds, target, config):
    pred = torch.sigmoid(preds)
    tp = pred * target
    
    fs = 1.3 * tp.sum(dim=(1, 2, 3)) / (pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) * 0.3)
    loss = 1 - fs.mean()
    
    return loss
    
def mse(preds, target, config):
    mse = nn.MSELoss(reduction='none')
    pred = torch.sigmoid(preds)
    loss = mse(pred, target).mean()
    return loss

def loss_to_dict(loss_config):
    loss_cluster = {}
    loss_terms = loss_config.split(',')
    for term in loss_terms:
        ts = term.split('#')
        if len(ts) == 1:
            ltag = ts[0]
            weight = 1
        elif len(ts) == 2:
            ltag, weight = ts
        else:
            print('Can not convert {} to a valid loss.'.format(term))
            return
        
        tag = ltag.split('_')
        if len(tag) == 1:
            loss_name = tag[0]
            ltype = 'sal'
        elif len(tag) == 2:
            loss_name, ltype = tag
        else:
            print('Can not convert {} to a valid loss.'.format(ltag))
            return
        
        if ltype not in loss_cluster.keys():
            loss_cluster[ltype] = []
            
        #loss_cluster[ltype].append([loss_dict[loss_name], float(weight)])
        loss_cluster[ltype].append([eval(loss_name), float(weight)])
        
    return loss_cluster


# loss are defined by --loss=loss1,loss2,loss3, where loss1 is formated as 'name_type#weight'.
# 'name' is one of keys in loss_dict, 'type' usuallly is one of ('sal', 'edge'), 'weight' is a float number.
class Loss_factory(nn.Module):
    def __init__(self, config):
        super(Loss_factory, self).__init__()
        self.loss_cluster = loss_to_dict(config['loss'])
        #self.loss_cluster['sal'] = loss_worker(loss_config, config['lw'].split(','))
        print(self.loss_cluster)
        
    def forward(self, preds, target, config):
        loss = 0
        for out_tag, loss_list in self.loss_cluster.items():
            if out_tag == 'edge':
                tar = label_edge_prediction(target)
            else:
                tar = target
            for pred in preds[out_tag]:
                for l_term, weight in loss_list:
                    #try:
                    loss += l_term(pred, tar, config) * weight
                    #except:
                    #    print(l_term.__name__)
        return loss
